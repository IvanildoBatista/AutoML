# -*- coding: utf-8 -*-
"""AutoML para previsão de Churn de clientes de uma empresa de telecomunicações.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VK5YLIrCFfi_kDAy5U-P5ROSayjy_2yI

# *Auto-Sklearn* para previsão de *Churn*

Nesse projeto eu irei aplicar a biblioteca de *Auto Machine Learning Auto-Sklearn* para gerar um modelo que preveja o *Churn* de clientes de uma empresa de Telecomunicações. A vantagem do processo de *Auto Machine Learning* é que todo processo de escolha, treinamento e *tunning* do modelo é algo automático, permitindo que tempo e esforço sejam aplicados para outras áreas do projeto.

#### O que é *churn* ?

*Churn* é uma métrica que indica o quanto uma empresa perdeu de receita ou clientes. Para calcular o *churn*, basta dividir a quantidade de clientes que perdeu até o final do período pelo total de clientes que iniciaram. Exemplo: se você perdeu 10 clientes de 100 = 10% de *churn rate*. Essa métrica também usada em departamentos de pessoas para analisar a rotatividade de funcionários de uma empresa em um determinado setor ou em toda a empresa.

## Dados

Os dados são da plataforma *Kaggle* e podem ser obtidos [aqui](https://www.kaggle.com/blastchar/telco-customer-churn). A base de dados conta com 7043 observações e 21 colunas.

Nessas *features* constam :

1) Clientes que saíram no último mês - a coluna é chamada de *churn*;

2) Serviços que cada cliente assinou - telefone, várias linhas, internet, segurança online, backup online, proteção de dispositivo, suporte técnico e streaming de TV e filmes;

3) Informações da conta do cliente - há quanto tempo ele é cliente, contrato, forma de pagamento, faturamento sem papel, cobranças mensais e cobranças totais;

4) e informações demográficas sobre clientes - sexo, faixa etária e se eles têm parceiros e dependentes;

**Descrição das variáveis**

1) *customerID* : Código do cliente;

2) *gender* : Gênero do cliente;

3) *SeniorCitizen* : Se o cliente é um cidadão idoso ou não (1, 0);

4) *Partner* : Se o cliente tem um parceiro ou não (Sim, Não);

5) *Dependents* : Se o cliente tem dependentes ou não (Sim, Não);

6) *tenure* : Número de meses que o cliente permaneceu na empresa; 

7) *PhoneService* : Se o cliente tem um serviço de telefone ou não (Sim, Não);

8) *MultipleLines* : Se o cliente tem várias linhas ou não (Sim, Não, Sem serviço telefônico);

9) *InternetService* : Provedor de serviços de Internet do cliente (DSL, fibra óptica, não);

10) *OnlineSecurity* : Se o cliente tem segurança online ou não (Sim, Não, Sem serviço de Internet);

11) *OnlineBackup* : Se o cliente tem backup online ou não (Sim, Não, Sem serviço de Internet);

12) *DeviceProtection* : Se o cliente tem proteção de dispositivo ou não (Sim, Não, Sem serviço de Internet);

13) *TechSupport* : Se o cliente tem suporte técnico ou não (Sim, Não, Sem serviço de Internet);

14) *StreamingTV* : Se o cliente tem *streaming* de TV ou não (Sim, Não, Sem serviço de Internet);

15) *StreamingMovies* : Se o cliente tem *streaming* de filmes ou não (Sim, Não, Sem serviço de Internet);

16) *Contract* : A vigência do contrato do cliente (mês a mês, um ano, dois anos);

17) *PaperlessBilling* : Se o cliente tem faturamento sem papel ou não (Sim, Não);

18) *PaymentMethod* : O método de pagamento do cliente (cheque eletrônico, cheque enviado, transferência bancária (automático),etc.;

19) *MonthlyCharges* : O valor cobrado do cliente mensalmente;

20) *TotalCharges* : O valor total cobrado do cliente;

21) *Churn* : Se o cliente mudou ou não (sim ou não).

## Instalação das bibliotecas
"""

!apt-get install swig -y
!pip install Cython numpy
!pip install auto-sklearn
!pip install dask[complete] distributed --upgrade
!pip install "dask[distributed]" --upgrade

!pip install -U imbalanced-learn

"""## Importando as bibliotecas"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import sklearn.metrics
import autosklearn.classification

from sklearn.model_selection import train_test_split
from sklearn.dummy import DummyClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import classification_report
from sklearn.metrics import plot_roc_curve

from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE, KMeansSMOTE,SMOTEN, SMOTENC, RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler, NearMiss, EditedNearestNeighbours, RepeatedEditedNearestNeighbours,AllKNN, CondensedNearestNeighbour
from imblearn.under_sampling import OneSidedSelection, NeighbourhoodCleaningRule, InstanceHardnessThreshold
from imblearn.combine import SMOTEENN, SMOTETomek

"""## Importação dos dados"""

churn = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn (1).csv')

"""## Análise Exploratória dos dados

Primeiras observações da base de dados.
"""

churn.head()

"""Últimas observações da base de dados."""

churn.tail()

"""Informações sobre as variáveis: Das 21 variáveis, 18 são objetos (valores não numéricos), por isso teremos que transformá-las em numéricas para que possam ser aplicadas no processo de *auto machine learning*."""

churn.info()

"""Número de valores únicos de cada coluna."""

churn.nunique()

"""Não há valores faltantes."""

churn.isna().sum()

print('Tabela estatística das variáveis numéricas')
display(churn.describe().T)
print(' '*508)
print("Tabela estatística das variáveis categóricas")
display(churn.describe(include='O').T)

"""Dimensão da base de dados."""

churn.shape

"""## Transformações dos dados

Antes de seguir para a análise gráfica é necessário transformar os dados para valores numéricos categóricos, pois muitos estão em formato de texto.

Antes irei excluir a coluna *customerID*, pois ele não é relevante para nossa modelagem.
"""

#Base que usarei para realizar a análise exploratória de dados
churn2=churn
churn2['Churn'] = LabelEncoder().fit_transform(churn2['Churn'])

churn = churn.drop('customerID', axis=1)

"""Selecionarei todas as colunas que são do tipo objeto.

Com o uso do *loop for* irei transformar as variáveis categóricas em numéricas categóricas.
"""

churn.select_dtypes(['int64','float64']).columns

lista3 = ['tenure','MonthlyCharges']
for i in lista3:
  churn[i] = (churn[i] - churn[i].mean())/(churn[i].std())

  #SeniorCitizen não é INT64
  #Transformar TotalCharges de object para Float

"""Transformando as variáveis objetos em variáveis numéricas."""

#churn['Churn'] = LabelEncoder().fit_transform(churn['Churn'])

for i in churn.select_dtypes('object').columns:
  churn[i] = LabelEncoder().fit_transform(churn[i])

"""Abaixo podemos ver que a transformação foi efetuada."""

churn.head()

"""E o tipo de dados da base também foi alterado para inteiro (*int64*)."""

churn.dtypes

"""Podemos seguir para análise gráfica dos dados.

### Análise gráfica

Conforme os gráficos de barras abaixo temos que:

1) Não aparenta haver diferença entre clientes que deixam a empresa quando tratamos de gênero;

2) Já para a variável *SeniorCitizen*, aqueles **não idosos** são maioria entre os que deixam de ser clientes da empresa.
"""

fig, ax=plt.subplots(1,2,figsize=(20,2.5))
ax[0].title.set_text('Gráfico de barras de Churn por gênero')
ax[1].title.set_text('Gráfico de barras de Churn se o cliente é idoso ou não')
sns.countplot(x='gender', data=churn2, hue='Churn', ax=ax[0])
sns.countplot(x='SeniorCitizen', data=churn2, hue='Churn', ax=ax[1]);

"""3) Na variável *MultipleLines*, quem possui e não possui múltiplas linhas telefônicas são os que mais deixam de ser clientes;

4) Em *PhoneService*, deixam de ser clientes aqueles indivíduos que possuem algum serviço telefônico.
"""

fig, ax=plt.subplots(1,2,figsize=(20,2.5))
ax[0].title.set_text('Gráfico de barras de Churn por MultipleLines')
ax[1].title.set_text('Gráfico de barras de Churn por PhoneService')
sns.countplot(x='MultipleLines', data=churn2, hue='Churn', ax=ax[0])
sns.countplot(x='PhoneService', data=churn2, hue='Churn', ax=ax[1]);

"""No gráfico abaixo vemos o número de meses que um cliente tem até deixar a empresa. Nos primeiros meses, são os meses em que há um maior *churn* de clientes (podemos ver que o primeiro ano como clientes é crucial) e em seguida a quantidade de clientes que deixam a empresa vai caindo."""

plt.figure(figsize=(20,5))
sns.countplot(x='tenure', data=churn2, hue='Churn')
plt.ylabel('')
plt.xlabel('Meses até o Churn',size=15)
plt.title('Quantidade de meses até o cliente deixar a empresa',size=15);

"""5) Em *InternetService*, a quantidade maior de *churn* vem de clientes que possuíam o serviço de Fibra Ótica;

6) E indivíduos que não possuem segurança *online* (*OnlineSecurity*), são os que mais deixam de ser clientes;
"""

fig, ax=plt.subplots(1,2,figsize=(20,2.5))
ax[0].title.set_text('Gráfico de barras de Churn por InternetService')
ax[1].title.set_text('Gráfico de barras de Churn por OnlineSecurity')
sns.countplot(x='InternetService', data=churn2, hue='Churn', ax=ax[0])
sns.countplot(x='OnlineSecurity', data=churn2, hue='Churn', ax=ax[1]);

"""7) Aqueles que não possuem *backup online* são os que mais deixam de ser clientes;

8) *DeviceProtection* : Clientes sem proteção de dispositivo são os que mais deixam de ser clientes;
"""

fig, ax=plt.subplots(1,2,figsize=(20,2.5))
ax[0].title.set_text('Gráfico de barras de Churn por OnlineBackup')
ax[1].title.set_text('Gráfico de barras de Churn por DeviceProtection')
sns.countplot(x='OnlineBackup', data=churn2, hue='Churn', ax=ax[0])
sns.countplot(x='DeviceProtection', data=churn2, hue='Churn', ax=ax[1]);

"""9) *TechSupport* : Quem não possui suporte técnico são os que mais deixam de serem clientes;

10) *StreamingTV* : Nessa variável que possui e não possui sistema de *Streaming* debandam da carteira de clientes da empresa;
"""

fig, ax=plt.subplots(1,2,figsize=(20,2.5))
ax[0].title.set_text('Gráfico de barras de Churn por TechSupport')
ax[1].title.set_text('Gráfico de barras de Churn por StreamingTV')
sns.countplot(x='TechSupport', data=churn2, hue='Churn', ax=ax[0])
sns.countplot(x='StreamingTV', data=churn2, hue='Churn', ax=ax[1]);

"""11) *StreamingMovies* : Resultado semelhante aos da variável *StreamingTV*;

12) Quem faz contrato mês a mês (*month-to-month*) são os que mais deixam de serem clientes;
"""

fig, ax=plt.subplots(1,2,figsize=(20,2.5))
ax[0].title.set_text('Gráfico de barras de Churn por StreamingMovies')
ax[1].title.set_text('Gráfico de barras de Churn por Contract')
sns.countplot(x='StreamingMovies', data=churn2, hue='Churn', ax=ax[0])
sns.countplot(x='Contract', data=churn2, hue='Churn', ax=ax[1]);

"""13) Quem tem faturamento sem papel são os que mais deixam de serem clientes;

14) *PaymentMethod* : Aqueles que pagam com cheque eletrônico são os que mais abandonam a carteira de clientes da empresa.
"""

fig, ax=plt.subplots(1,2,figsize=(20,2.5))
ax[0].title.set_text('Gráfico de barras de Churn por PaperlessBilling')
ax[1].title.set_text('Gráfico de barras de Churn por PaymentMethod')
sns.countplot(x='PaperlessBilling', data=churn2, hue='Churn', ax=ax[0])
sns.countplot(x='PaymentMethod', data=churn2, hue='Churn', ax=ax[1]);

"""Abaixo pode-se pobservar o histograma e o *boxplot* da variável *MonthlyCharges*.

A distribuição dos dados não possui a aparência de uma distribuição normal (formato de sino) e o seu *boxplot* não mostra a presenta de valores discrepantes nos dados (*outliers*).
"""

fig, ax = plt.subplots(1,2,figsize=(20,5))
ax[0].title.set_text('Histograma da variável MonthlyCharges')
ax[1].title.set_text('Boxplot da variável MonthlyCharges')
sns.histplot(x='MonthlyCharges', data=churn2, ax=ax[0])
sns.boxplot(x='MonthlyCharges', data=churn2, ax=ax[1]);

"""## Modelagem de dados

Separando as *features* e a variável *target* (alvo).
"""

X=churn.drop(["Churn",'TotalCharges'],axis=1)
y=churn['Churn']

"""Um dos problemas da variável *Churn* as suas classes estão desbalanceadas e isso traz um problema na momento de treino do algoritmo em que o modelo irá aprender mais de um padrão de uma classe do que da outra. Para solucionar esse problema é necessário realizar um procedimento chamado de rebalanceamento das classes, que pode ser aumentando artificialmente o número de observações da classe minoritária (*Oversampling*), ou minimizando o número de observações da classe marjoritária (*Undersampling*) ou combinando essas técnicas.

Abaixo vemos o desbalancemento das classes: temos mais da classe 0 do que a classe 1 (que é a que queremos prever - se o cliente deixa ou não a empresa).
"""

plt.figure(figsize=(20,5))
plt.title('Classes da variável Churn desbalanceadas', size=15)
sns.countplot(x='Churn', data=churn2)
plt.xlabel('Classes', size=15)
plt.ylabel('');

"""Rebalanceamento das classes com vários algoritmos de reamostragem de dados. Aqui irei aplicar model0s de *Oversampling*, de *Undersampling* e dessas duas técnicas de forma combinada."""

#Algoritmos de Oversampling
X1,y1=SMOTE().fit_resample(X,y)
X2,y2=ADASYN().fit_resample(X,y)
X3,y3=BorderlineSMOTE().fit_resample(X,y)
X4,y4=SVMSMOTE().fit_resample(X,y)
X5,y5=KMeansSMOTE().fit_resample(X,y)
X6,y6=SMOTEN().fit_resample(X,y)
#X7,y7=SMOTENC().fit_resample(X,y)
X8,y8=RandomOverSampler().fit_resample(X,y)

#Algoritmos de Undersampling
X9,y9=RandomUnderSampler().fit_resample(X,y)
X10,y10=NearMiss().fit_resample(X,y)
X11,y11=EditedNearestNeighbours().fit_resample(X,y)
X12,y12=RepeatedEditedNearestNeighbours().fit_resample(X,y)
X13,y13=AllKNN().fit_resample(X,y)
#X14,y14=CondensedNearestNeighbour().fit_resample(X,y)
X15,y15=OneSidedSelection().fit_resample(X,y)
X16,y16=NeighbourhoodCleaningRule().fit_resample(X,y)
X17,y17=InstanceHardnessThreshold().fit_resample(X,y)

#Técnicas combinadas
X18,y18=SMOTEENN().fit_resample(X,y)
X19,y19=SMOTETomek().fit_resample(X,y)

"""Exemplo de reamostragem dos dados."""

fig, ax = plt.subplots(1,2, figsize=(20,5))
sns.countplot(x='Churn', data=pd.DataFrame(y), ax=ax[0])
sns.countplot(x='Churn', data = pd.DataFrame(y9), ax=ax[1]);

"""Separando os dados de treino e de teste."""

X_treino, X_teste, y_treino, y_teste = train_test_split(X,y, random_state=42)
X_treino1, X_teste1, y_treino1, y_teste1 = train_test_split(X1,y1, random_state=42)
X_treino2, X_teste2, y_treino2, y_teste2 = train_test_split(X2,y2, random_state=42)
X_treino3, X_teste3, y_treino3, y_teste3 = train_test_split(X3,y3, random_state=42)
X_treino4, X_teste4, y_treino4, y_teste4 = train_test_split(X4,y4, random_state=42)
X_treino5, X_teste5, y_treino5, y_teste5 = train_test_split(X5,y5, random_state=42)
X_treino6, X_teste6, y_treino6, y_teste6 = train_test_split(X6,y6, random_state=42)
X_treino8, X_teste8, y_treino8, y_teste8 = train_test_split(X8,y8, random_state=42)
X_treino9, X_teste9, y_treino9, y_teste9 = train_test_split(X9,y9, random_state=42)
X_treino10, X_teste10, y_treino10, y_teste10 = train_test_split(X10,y10, random_state=42)
X_treino11, X_teste11, y_treino11, y_teste11 = train_test_split(X11,y11, random_state=42)
X_treino12, X_teste12, y_treino12, y_teste12 = train_test_split(X12,y12, random_state=42)
X_treino13, X_teste13, y_treino13, y_teste13 = train_test_split(X13,y13, random_state=42)
X_treino15, X_teste15, y_treino15, y_teste15 = train_test_split(X15,y15, random_state=42)
X_treino16, X_teste16, y_treino16, y_teste16 = train_test_split(X16,y16, random_state=42)
X_treino17, X_teste17, y_treino17, y_teste17 = train_test_split(X17,y17, random_state=42)
X_treino18, X_teste18, y_treino18, y_teste18 = train_test_split(X18,y18, random_state=42)
X_treino19, X_teste19, y_treino19, y_teste19 = train_test_split(X19,y19, random_state=42)

"""### Treinando os modelos"""

#Instanciando o modelo
automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl.fit(pd.DataFrame(X_treino), pd.DataFrame(y_treino), dataset_name='churn')

automl1 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl1.fit(pd.DataFrame(X_treino1), pd.DataFrame(y_treino1), dataset_name='churn')

automl2 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl2.fit(pd.DataFrame(X_treino2), pd.DataFrame(y_treino2), dataset_name='churn')

automl3 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl3.fit(pd.DataFrame(X_treino3), pd.DataFrame(y_treino3), dataset_name='churn')

automl4 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl4.fit(pd.DataFrame(X_treino4), pd.DataFrame(y_treino4), dataset_name='churn')

automl5 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl5.fit(pd.DataFrame(X_treino5), pd.DataFrame(y_treino5), dataset_name='churn')

automl6 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl6.fit(pd.DataFrame(X_treino6), pd.DataFrame(y_treino6), dataset_name='churn')

automl8 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl8.fit(pd.DataFrame(X_treino8), pd.DataFrame(y_treino8), dataset_name='churn')

automl9 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl9.fit(pd.DataFrame(X_treino9), pd.DataFrame(y_treino9), dataset_name='churn')

automl10 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl10.fit(pd.DataFrame(X_treino10), pd.DataFrame(y_treino10), dataset_name='churn')

automl11 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl11.fit(pd.DataFrame(X_treino11), pd.DataFrame(y_treino11), dataset_name='churn')

automl12 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl12.fit(pd.DataFrame(X_treino12), pd.DataFrame(y_treino12), dataset_name='churn')

automl13 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl13.fit(pd.DataFrame(X_treino13), pd.DataFrame(y_treino13), dataset_name='churn')

automl15 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl15.fit(pd.DataFrame(X_treino15), pd.DataFrame(y_treino15), dataset_name='churn')

automl16 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl16.fit(pd.DataFrame(X_treino16), pd.DataFrame(y_treino16), dataset_name='churn')

automl17 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl17.fit(pd.DataFrame(X_treino17), pd.DataFrame(y_treino17), dataset_name='churn')

automl18 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl18.fit(pd.DataFrame(X_treino18), pd.DataFrame(y_treino18), dataset_name='churn')

automl19 = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl19.fit(pd.DataFrame(X_treino19), pd.DataFrame(y_treino19), dataset_name='churn')

automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=30)
automl.fit(pd.DataFrame(X_treino), pd.DataFrame(y_treino), dataset_name='churn')

"""Imprimindo os modelos"""

#print(automl.show_models())

print(automl1.show_models())

print(automl2.show_models())

print(automl3.show_models())

print(automl4.show_models())

print(automl5.show_models())

print(automl6.show_models())

print(automl8.show_models())

print(automl9.show_models())

print(automl10.show_models())

print(automl11.show_models())

print(automl12.show_models())

print(automl13.show_models())

#print(automl15.show_models())

print(automl16.show_models())

print(automl17.show_models())

print(automl18.show_models())

print(automl19.show_models())

"""### Avaliação dos Modelos

Abaixo podemos ver o desempenho de cada modelo pela métrica de acurácia. O melhor modelo foi o 17 que usou a algoritmo de *undersampling* *InstanceHardnessThreshold*.
"""

print("Acurácia dos modelos")
print(""*254)
print('Modelos com Algoritmos de Oversampling')
predictions = automl.predict(X_teste)
print("Acurária do modelo principal:", sklearn.metrics.accuracy_score(y_teste, predictions))

predictions1 = automl1.predict(X_teste1)
print("Acurária do modelo 1:", sklearn.metrics.accuracy_score(y_teste1, predictions1))

predictions2 = automl2.predict(X_teste2)
print("Acurária do modelo 2:", sklearn.metrics.accuracy_score(y_teste2, predictions2))

predictions3 = automl3.predict(X_teste3)
print("Acurária do modelo 3:", sklearn.metrics.accuracy_score(y_teste3, predictions3))

predictions4 = automl4.predict(X_teste4)
print("Acurária do modelo 4:", sklearn.metrics.accuracy_score(y_teste4, predictions4))

predictions5 = automl5.predict(X_teste5)
print("Acurária do modelo 5:", sklearn.metrics.accuracy_score(y_teste5, predictions5))

predictions6 = automl6.predict(X_teste6)
print("Acurária do modelo 6:", sklearn.metrics.accuracy_score(y_teste6, predictions6))

predictions8 = automl8.predict(X_teste8)
print("Acurária do modelo 8:", sklearn.metrics.accuracy_score(y_teste8, predictions8))

print(""*254)
print('Modelos com Algoritmos de Undersampling')
predictions9 = automl9.predict(X_teste9)
print("Acurária do modelo 9:", sklearn.metrics.accuracy_score(y_teste9, predictions9))

predictions10 = automl10.predict(X_teste10)
print("Acurária do modelo 10:", sklearn.metrics.accuracy_score(y_teste10, predictions10))

predictions11 = automl11.predict(X_teste11)
print("Acurária do modelo 11:", sklearn.metrics.accuracy_score(y_teste11, predictions11))

predictions12 = automl12.predict(X_teste12)
print("Acurária do modelo 12:", sklearn.metrics.accuracy_score(y_teste12, predictions12))

predictions13 = automl13.predict(X_teste13)
print("Acurária do modelo 13:", sklearn.metrics.accuracy_score(y_teste13, predictions13))

predictions15 = automl15.predict(X_teste15)
print("Acurária do modelo 15:", sklearn.metrics.accuracy_score(y_teste15, predictions15))

predictions16 = automl16.predict(X_teste16)
print("Acurária do modelo 16:", sklearn.metrics.accuracy_score(y_teste16, predictions16))

predictions17 = automl17.predict(X_teste17)
print("Acurária do modelo 17:", sklearn.metrics.accuracy_score(y_teste17, predictions17))

print(""*254)
print('Modelos com Algoritmos de Técnica combinadas')
predictions18 = automl18.predict(X_teste18)
print("Acurária do modelo 18:", sklearn.metrics.accuracy_score(y_teste18, predictions18))

predictions19 = automl19.predict(X_teste19)
print("Acurária do modelo 19:", sklearn.metrics.accuracy_score(y_teste19, predictions19))

"""Abaixo vamos ver a diferença de desempenho dos modelos em seus dados de treino e de teste para saber se há algum problema de *overfitting* (sobreajuste do modelo) ou *underfitting* (subajuste do modelo), pois o que quero é um modelo que possa ser generalizável.

Novamente o modelo 17 ( que usa o algoritmo *InstanceHardnessThreshold*) de o melhor resultado.
"""

print('Training score do modelo principal:',round(automl.score(X_treino,y_treino)*100,3),'%')
print('Testing score do modelo principal:',round(automl.score(X_teste,y_teste)*100,3),'%')
print(''*254)

print('Training score do modelo 1:',round(automl1.score(X_treino1,y_treino1)*100,3),'%')
print('Testing score do modelo 1:',round(automl1.score(X_teste1,y_teste1)*100,3),'%')
print(''*254)

print('Training score do modelo 2:',round(automl2.score(X_treino2,y_treino2)*100,3),'%')
print('Testing score do modelo 2:',round(automl2.score(X_teste2,y_teste2)*100,3),'%')
print(''*254)

print('Training score do modelo 3:',round(automl3.score(X_treino3,y_treino3)*100,3),'%')
print('Testing score do modelo 3:',round(automl3.score(X_teste3,y_teste3)*100,3),'%')
print(''*254)

print('Training score do modelo 4:',round(automl4.score(X_treino4,y_treino4)*100,3),'%')
print('Testing score do modelo 4:',round(automl4.score(X_teste4,y_teste4)*100,3),'%')
print(''*254)

print('Training score do modelo 5:',round(automl5.score(X_treino5,y_treino5)*100,3),'%')
print('Testing score do modelo 5:',round(automl5.score(X_teste5,y_teste5)*100,3),'%')
print(''*254)

print('Training score do modelo 6:',round(automl6.score(X_treino6,y_treino6)*100,3),'%')
print('Testing score do modelo 6:',round(automl6.score(X_teste6,y_teste6)*100,3),'%')
print(''*254)

print('Training score do modelo 8:',round(automl8.score(X_treino8,y_treino8)*100,3),'%')
print('Testing score do modelo 8:',round(automl8.score(X_teste8,y_teste8)*100,3),'%')
print(''*254)

print('Training score do modelo 9:',round(automl9.score(X_treino9,y_treino9)*100,3),'%')
print('Testing score do modelo 9:',round(automl9.score(X_teste9,y_teste9)*100,3),'%')
print(''*254)

print('Training score do modelo 10:',round(automl10.score(X_treino10,y_treino10)*100,3),'%')
print('Testing score do modelo 10:',round(automl10.score(X_teste10,y_teste10)*100,3),'%')
print(''*254)

print('Training score do modelo 11:',round(automl11.score(X_treino11,y_treino11)*100,3),'%')
print('Testing score do modelo 11:',round(automl11.score(X_teste11,y_teste11)*100,3),'%')
print(''*254)

print('Training score do modelo 12:',round(automl12.score(X_treino12,y_treino12)*100,3),'%')
print('Testing score do modelo 12:',round(automl12.score(X_teste12,y_teste12)*100,3),'%')
print(''*254)

print('Training score do modelo 13:',round(automl13.score(X_treino13,y_treino13)*100,3),'%')
print('Testing score do modelo 13:',round(automl13.score(X_teste13,y_teste13)*100,3),'%')
print(''*254)

print('Training score do modelo 15:',round(automl15.score(X_treino15,y_treino15)*100,3),'%')
print('Testing score do modelo 15:',round(automl15.score(X_teste15,y_teste15)*100,3),'%')
print(''*254)

print('Training score do modelo 16:',round(automl16.score(X_treino16,y_treino16)*100,3),'%')
print('Testing score do modelo 16:',round(automl16.score(X_teste16,y_teste16)*100,3),'%')
print(''*254)

print('Training score do modelo 17:',round(automl17.score(X_treino17,y_treino17)*100,3),'%')
print('Testing score do modelo 17:',round(automl17.score(X_teste17,y_teste17)*100,3),'%')
print(''*254)

print('Training score do modelo 18:',round(automl18.score(X_treino18,y_treino18)*100,3),'%')
print('Testing score do modelo 18:',round(automl18.score(X_teste18,y_teste18)*100,3),'%')
print(''*254)

print('Training score do modelo 19:',round(automl19.score(X_treino19,y_treino19)*100,3),'%')
print('Testing score do modelo 19:',round(automl19.score(X_teste19,y_teste19)*100,3),'%')

"""#### Relatórios dos melhores modelos

Aqui só serão analisados as métricas de avaliação dos modelos que tiveram melhor desempenho anteriormente. Destaquei os modelos 12, 13, 17 e 18.

Abaixo podemos ver o relatório das métricas do modelo 12 e é importante notar aqui que tanto a precisão das classes (*precision*) quanto a sensibilidade (*recall*) estão bem próximos; e as métricas desse modelo estão acima de 90%, que mostra que esse é um bom modelo preditor.
"""

valor_classe=[0,1]
print(classification_report(y12,cross_val_predict(automl12,X12,y12,cv=10),valor_classe))

"""O modelo 13 já possui um desempenho menor na classe 1 (deixou de ser cliente), mas a suas métricas estão bem próximas uma das outras e bem próximas de 90% no geral."""

valor_classe=[0,1]
print(classification_report(y13,cross_val_predict(automl13,X13,y13,cv=10),valor_classe))

"""O desempenho do modelo 18 foi um pouco pior na classe 0, mas teve um bom resultado para prever a classe 1 (93% de precisão e 90% de *recall*)."""

valor_classe=[0,1]
print(classification_report(y18,cross_val_predict(automl18,X18,y18,cv=10),valor_classe))

"""O modelo 17 foi o melhor, tanto em acurácia, como em *testing score* e *training score*, com nas métricas de precisão e *recall*.

Esse modelo está usando uma técnica de reamostragem *undersampling*, ou seja, houve uma redução nos dados de marjoritários.
"""

valor_classe=[0,1]
print(classification_report(y17,cross_val_predict(automl17,X17,y17,cv=10),valor_classe))

"""#### Matrizes de confusão

Uma outra forma de avaliar o desempenho dos modelos é usar a matriz de confusão, que compara os valores preditos com os valores reais de forma visual.
"""

fig, ax= plt.subplots(2,2, figsize=(20,10))
disp=plot_confusion_matrix(automl12,X_teste12,y_teste12,cmap='Blues',values_format='.5g', ax=ax[0][0])
disp=plot_confusion_matrix(automl13,X_teste13,y_teste13,cmap='Reds',values_format='.5g', ax=ax[0][1])
disp=plot_confusion_matrix(automl17,X_teste17,y_teste17,cmap='Greens',values_format='.5g', ax=ax[1][0])
disp=plot_confusion_matrix(automl18,X_teste18,y_teste18,cmap='Oranges',values_format='.5g', ax=ax[1][1])

"""#### Curva *ROC* e AUC

Por fim, vamos plotar a curva *ROC* e gerar o AUC.

A curva ROC mostra o quão bom o modelo criado pode distinguir entre duas coisas (já que é utilizado para classificação). Essas duas coisas podem ser 0 ou 1, ou positivo e negativo. Os melhores modelos conseguem distinguir com precisão o binômio.

A curva *ROC* possui dois parâmetros:

1) Taxa de verdadeiro positivo (True Positive Rate), que é dado por 

$\frac{true positives}{(true positives + false negatives)}$

Taxa de falso positivo (False Positive Rate), que é dado por $\frac{false positives}{(true positives + false negatives)}$

O valor do AUC varia de 0.0 até 1.0 e é a área abaixo da curva *ROC*, tendo comoo limiar entre as classes o valor de 0.5. Ou seja, acima desse limite, o algoritmo classifica em uma classe e abaixo na outra classe.

Abaixo geramos as curvas *ROC* e os valores de *AUC* para cada modelo treinado. Vê-se que o melhor modelo foi o 17.
"""

plt.figure(figsize=(20,10))
disp=plot_roc_curve(automl,X_teste,y_teste)
plot_roc_curve(automl12,X_teste12,y_teste12, ax=disp.ax_);
plot_roc_curve(automl13,X_teste13,y_teste13, ax=disp.ax_);
plot_roc_curve(automl17,X_teste17,y_teste17, ax=disp.ax_);
plot_roc_curve(automl18,X_teste18,y_teste18, ax=disp.ax_);
plt.show()

"""## Conclusão

Nesse pequeno projeto apliquei a biblioteca *Auto-Sklearn* para modelagem de dados de *churn* de clientes de uma empresa e classificá-los com base nas suas *features*. O uso dessa ferramenta também dispensou a uso de vários modelos de classificação.

Além disso, utilizei algoritmos da biblioteca *imblearn* para reamostragem dos dados, pois as classes da variável alvo *Churn* estavam desbalanceadas.

Encontrei, então, um modelo que classifica a classe 1 com uma acurácia de 93%, precisão de 97%, *recall* de 94% e um AUC de 98%.
"""